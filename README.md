# ğŸ“ Explainable AI Deepfake Detection  
**Using CNNs + SHAP to Detect AI-Generated Imagery**  
*Sara Alghamdi | MSc Artificial Intelligence â€“ Aston University*



## ğŸ“Œ Project Summary

This project demonstrates how a custom-built **Convolutional Neural Network (CNN)** combined with **SHAP (SHapley Additive exPlanations)** can accurately detect and explain AI-generated (deepfake) imagery.

- ğŸ” Binary classification: Real vs. AI-generated images  
- ğŸ“Š 92.94% Accuracy | 0.981 AUC  
- ğŸ’¡ Fully explainable using SHAP XAI visualizations  
- ğŸ§  Dataset: CIFAR-10 (real) + Synthetic (Stable Diffusion-based)

---

## ğŸ” Features

- âœ… Convolutional Neural Network (CNN) in TensorFlow/Keras  
- âœ… SHAP (XAI) for visualizing feature importance  
- âœ… Trained on 120,000 images (100K training / 20K test)  
- âœ… Includes evaluation metrics + confusion matrix + SHAP heatmaps
